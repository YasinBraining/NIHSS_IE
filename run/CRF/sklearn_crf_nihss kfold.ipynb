{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from itertools import chain\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy. stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_table('训练语料/train/train_data.txt',names=['id','word','entity','tag'])\n",
    "test=pd.read_table('训练语料/test/test_data.txt',names=['id','word','entity','tag'])\n",
    "validf=pd.read_table('训练语料/test/test_data_label.txt', names=['id','word','entity','tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.dropna(subset=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test), len(validf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_56_motor(df):\n",
    "    l=df['tag']\n",
    "    ldx56motor=[]\n",
    "    for i in range(len(df)):\n",
    "        if '56_Motor' in l[i] or 'TemporalConstraint' in l[i]:\n",
    "            ldx56motor.append(i)\n",
    "    newdf=df.drop(ldx56motor, axis=0)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=remove_56_motor(train)\n",
    "validf=remove_56_motor(validf)\n",
    "print(len(train),len(validf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels=list(set(train['tag']))\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_id_list(pkl_file_type,num):\n",
    "    pkl_file_name = 'nihss_'+ pkl_file_type +'_fold_'+str(num)\n",
    "    with open('训练语料/train/' + pkl_file_name + '.pkl', 'rb') as f:\n",
    "        nihss_train_fold_0 = pickle.load(f)\n",
    "    id_list = []\n",
    "    for i in nihss_train_fold_0:\n",
    "        x = i['HADM_ID']\n",
    "        id_list.append(x)\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "traindf0 = train[train.id.isin(dataset_id_list('train',0))]\n",
    "traindf1 = train[train.id.isin(dataset_id_list('train',1))]\n",
    "traindf2 = train[train.id.isin(dataset_id_list('train',2))]\n",
    "traindf3 = train[train.id.isin(dataset_id_list('train',3))]\n",
    "traindf4 = train[train.id.isin(dataset_id_list('train',4))]\n",
    "\n",
    "# validating set\n",
    "testdf0 = train[train.id.isin(dataset_id_list('valid',0))]\n",
    "testdf1 = train[train.id.isin(dataset_id_list('valid',1))]\n",
    "testdf2 = train[train.id.isin(dataset_id_list('valid',2))]\n",
    "testdf3 = train[train.id.isin(dataset_id_list('valid',3))]\n",
    "testdf4 = train[train.id.isin(dataset_id_list('valid',4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindf0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2list2(df):\n",
    "    train_sents=[]\n",
    "    for i in set(df['id']):\n",
    "        ltrain=[]\n",
    "        sdf=df[df['id']==i]\n",
    "        for j in range(len(sdf)):\n",
    "            s=tuple(sdf.iloc[j,1:4])\n",
    "            #print(s)\n",
    "            ltrain.append(s)\n",
    "        train_sents.append(ltrain)\n",
    "    return train_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent,i):\n",
    "    word=sent[i][0]\n",
    "    postag=sent[i][1]\n",
    "    \n",
    "    features={\n",
    "        'bias':1.0,\n",
    "        'word.lower()':word.lower(),\n",
    "        'word[-3:]':word[-3:],\n",
    "        'word[-2:]':word[-2:],\n",
    "        'word.isupper()':word.isupper(),\n",
    "        'word.istitle()':word.istitle(),\n",
    "        'word.isdigit()':word.isdigit(),\n",
    "        #'postag[:2]':postag[:2],\n",
    "    }\n",
    "    if i>0:\n",
    "        word1=sent[i-1][0]\n",
    "        postag1=sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()':word1.lower(),\n",
    "            '-1:word.istitle()':word1.istitle(),\n",
    "            '-1:word.isupper()':word1.isupper(),\n",
    "            #'-1:postag':postag1,\n",
    "            #'-1:postag[:2]':postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS']=True\n",
    "        \n",
    "    if i<len(sent)-1:\n",
    "        word1=sent[i+1][0]\n",
    "        #print(i,word1)\n",
    "        postag1=sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()':word1.lower(),\n",
    "            '+1:word.istitle()':word1.istitle(),\n",
    "            '+1:word.isupper()':word1.isupper(),\n",
    "            #'+1:postag':postag1,\n",
    "            #'+1:postag[:2]':postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS']=True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_set=df2list2(validf)\n",
    "vali_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract features from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train,y_train):\n",
    "    %%time\n",
    "    crf=sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(X_train, y_train)\n",
    "    return crf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2tag(sent_list):\n",
    "    sent2tag_list=[]\n",
    "    for i in sent_list:\n",
    "        sent2tag_list=sent2tag_list+i\n",
    "    return sent2tag_list\n",
    "\n",
    "def tag2entity(sent_list):\n",
    "    tag2entity_list=[]\n",
    "    for j in sent2tag(sent_list):\n",
    "        if j=='O':\n",
    "            tag2entity_list.append([j])\n",
    "        elif j[0]=='B':\n",
    "            tag2entity_list.append([j])\n",
    "        elif j[0]=='I':\n",
    "            tag2entity_list[len(tag2entity_list)-1].append(j)\n",
    "    return tag2entity_list\n",
    "\n",
    "#def tag2entity_pred(sent_list,y_pred):\n",
    "#    tag2entity_pred_list=[]\n",
    "#    x=0\n",
    "#    for i in tag2entity(sent_list):\n",
    "#        tag2entity_pred_list.append(sent2tag(y_pred)[x:x+len(i)])\n",
    "#        x+=len(i)\n",
    "#    return tag2entity_pred_list\n",
    "        \n",
    "def entity2label(tag2entity_list):\n",
    "    entity2label_list=[]\n",
    "    for k in tag2entity_list:\n",
    "        #print(k)\n",
    "        l=[]\n",
    "        for m in k:\n",
    "            lm=m.split('-')\n",
    "            l.append(lm[len(lm)-1])\n",
    "        if len(set(l))==1:\n",
    "            entity2label_list.append(l[0])\n",
    "        elif len(set(l))>1:\n",
    "            entity2label_list.append(','.join(set(l)))  \n",
    "            #print(','.join(set(l)))\n",
    "    return entity2label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag2entity_pred(sent_list_test, sent_list_pred):\n",
    "    tag2entity_pred_list=[]\n",
    "    tag2entity_list=tag2entity(sent_list_test)\n",
    "    sent2tag_pred_list=sent2tag(sent_list_pred)\n",
    "    x=0\n",
    "    for i in tag2entity_list:\n",
    "        tag2entity_pred_list.append(sent2tag_pred_list[x:x+len(i)])\n",
    "        x+=len(i)\n",
    "    return tag2entity_pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate precision recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision: corrected predicted nihss entitiy / all entity predicted as nihss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_perf(test_label,pred_label):\n",
    "    tp=0\n",
    "    for i in range(len(test_label)):\n",
    "        if test_label[i]==pred_label[i] and test_label[i]!='O':\n",
    "            tp+=1\n",
    "    while 'O' in test_label:\n",
    "        test_label.remove('O')\n",
    "    rp=len(test_label)\n",
    "    \n",
    "    while 'O' in pred_label:\n",
    "        pred_label.remove('O')\n",
    "    pp=len(pred_label)\n",
    "    precision=tp/pp\n",
    "    recall=tp/rp\n",
    "    f1=2*(precision*recall)/(precision+recall)\n",
    "    overall_df=pd.DataFrame(data={'precision':precision, 'recall':recall, 'f1':f1}, index=['overall'])\n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_vali(traindf,testdf,validf):\n",
    "    train_set=df2list2(traindf)\n",
    "    test_set=df2list2(testdf)\n",
    "    vali_set=df2list2(validf)\n",
    "    \n",
    "    X_train=[sent2features(s) for s in train_set]\n",
    "    y_train=[sent2labels(s) for s in train_set]\n",
    "    X_test=[sent2features(s) for s in test_set]\n",
    "    y_test=[sent2labels(s) for s in test_set]\n",
    "    X_vali=[sent2features(s) for s in vali_set]\n",
    "    y_vali=[sent2labels(s) for s in vali_set]\n",
    "    \n",
    "    #crf=sklearn_crfsuite.CRF(\n",
    "        #algorithm='lbfgs',\n",
    "        #c1=0.1,\n",
    "        #c2=0.1,\n",
    "        #max_iterations=100,\n",
    "        #all_possible_transitions=True\n",
    "    #)\n",
    "    #crf.fit(X_train, y_train)\n",
    "    \n",
    "    #labels=list(crf.classes_)\n",
    "    #labels.remove('O')\n",
    "    #label_set=[x.split('-')[1] for x in labels]\n",
    "    label_set=list(set(traindf['tag']))\n",
    "    label_set.remove('O')\n",
    "    \n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs', \n",
    "        max_iterations=100, \n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    params_space = {\n",
    "        'c1': scipy.stats.expon(scale=0.5),\n",
    "        'c2': scipy.stats.expon(scale=0.05),\n",
    "    }\n",
    "    \n",
    "    # use the same metric for evaluation\n",
    "    f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                            average='weighted', labels=label_set)\n",
    "\n",
    "    # search\n",
    "    rs = RandomizedSearchCV(crf, params_space, \n",
    "                            #cv=3,  #cv default value is 5\n",
    "                            verbose=1, \n",
    "                            n_jobs=-1, \n",
    "                            n_iter=50, \n",
    "                            scoring=f1_scorer)\n",
    "    rs.fit(X_train, y_train)\n",
    "    crf=rs.best_estimator_\n",
    "    y_pred_vali=crf.predict(X_vali)\n",
    "\n",
    "    #y_pred=crf.predict(X_test)\n",
    "    #f1_score=metrics.flat_f1_score(y_test, y_pred, average='weighted',labels=labels)\n",
    "    #print('f1:',f1_score)\n",
    "    \n",
    "    y_vali_label=entity2label(tag2entity(y_vali))\n",
    "    y_pred_vali_label=entity2label(tag2entity_pred(y_vali, y_pred_vali))\n",
    "    \n",
    "    performance=perfm(y_vali_label,y_pred_vali_label)\n",
    "    overalldf=overall_perf(y_vali_label,y_pred_vali_label)\n",
    "    performance=performance.append(overalldf)\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfm(y_real,y_pred):\n",
    "    TP_dict=dict()\n",
    "    PP_dict=dict()\n",
    "    RP_dict=dict()\n",
    "    label_set = list(set(y_real))\n",
    "    label_set.remove('O')\n",
    "    \n",
    "    for i in [TP_dict,PP_dict, RP_dict]:\n",
    "        for j in label_set:\n",
    "            i[j]=0\n",
    "    \n",
    "    for i in range(len(y_real)):\n",
    "        if y_real[i]==y_pred[i] and y_real[i]!='O':\n",
    "            TP_dict[y_real[i]]+=1\n",
    "    for i in y_pred:\n",
    "        if i in label_set:\n",
    "            PP_dict[i]+=1\n",
    "    #print(PP_dict)\n",
    "    for i in y_real:\n",
    "        if i in label_set:\n",
    "            RP_dict[i]+=1\n",
    "            \n",
    "    precision_dict=dict()\n",
    "    recall_dict=dict()\n",
    "    f1_dict=dict()\n",
    "    for i in label_set:\n",
    "        if PP_dict[i]==0:\n",
    "            precision_dict[i]=0\n",
    "        else:   \n",
    "            precision_dict[i]=TP_dict[i]/PP_dict[i]\n",
    "        if RP_dict[i]==0:\n",
    "            recall_dict[i]=0\n",
    "        else:\n",
    "            recall_dict[i]=TP_dict[i]/RP_dict[i]\n",
    "        if (precision_dict[i]+recall_dict[i])==0:\n",
    "            f1_dict[i]=0\n",
    "        else:\n",
    "            f1_dict[i]=2*(precision_dict[i]*recall_dict[i])/(precision_dict[i]+recall_dict[i])\n",
    "    \n",
    "    precision_df=pd.DataFrame(precision_dict, index=['precision'])\n",
    "    recall_df=pd.DataFrame(recall_dict, index=['recall'])\n",
    "    f1_df=pd.DataFrame(f1_dict, index=['f1'])\n",
    "    perf_df=pd.concat([precision_df, recall_df,f1_df])\n",
    "    perf_dft=pd.DataFrame(perf_df.values.T, index=perf_df.columns, columns=perf_df.index)\n",
    "    return perf_dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_test_vali(traindf1,testdf1,validf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=0\n",
    "for i,j,k in [(traindf0,testdf0,'fold0'),(traindf1,testdf1,'fold1'),(traindf2,testdf2,'fold2'),(traindf3,testdf3,'fold3'),(traindf4,testdf4,'fold4')]:\n",
    "    print(y)\n",
    "    if y==0:\n",
    "        df=train_test_vali(i,j,validf)\n",
    "        y+=1\n",
    "    else:\n",
    "        dfy=train_test_vali(i,j,validf)\n",
    "        dfy.columns=[i+k for i in dfy.columns]\n",
    "        df=pd.concat([df,dfy], axis=1, join_axes=[df.index])\n",
    "        y+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_precision']=df.apply(lambda x: (x.precisionfold0+x.precisionfold1+x.precisionfold2+x.precisionfold3+x.precisionfold4)/5)\n",
    "df['average_recall']=df.apply(lambda x: (x.recallfold0+x.recallfold1+x.recallfold2+x.recallfold3+x.recallfold4)/5)\n",
    "df['average_f1']=df.apply(lambda x: (x.f1fold0+x.f1fold1+x.f1fold2+x.f1fold3+x.f1fold4)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('performance_vali_without56motor_tempreal_constraint test cv3 9 18.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
